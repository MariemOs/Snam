{"metadata":{"name":"Projet-BigDataML1","user_save_timestamp":"1970-01-01T01:00:00.000Z","auto_save_timestamp":"1970-01-01T01:00:00.000Z","language_info":{"name":"scala","file_extension":"scala","codemirror_mode":"text/x-scala"},"trusted":true,"customLocalRepo":"/tmp/repo","customRepos":["spartakus % default % http://dl.bintray.com/spark-clustering-notebook/maven % maven"],"customDeps":["com.github.haifengl % smile-scala_2.11 % 1.2.0"],"customImports":null,"customArgs":null,"customSparkConf":null},"cells":[{"metadata":{"id":"38C9096A295B427482181585A6B37E25"},"cell_type":"markdown","source":"\n#Groupe:\nNom et prénom, mail \n"},{"metadata":{"id":"318821C71D7E43A08A85D16FE3F193F8"},"cell_type":"markdown","source":"#Projet apprentissage automatique et écosystème Big Data"},{"metadata":{"id":"6795892BA59943A98956F19FC9C52DD3"},"cell_type":"markdown","source":"L'objectif du projet est de reproduire quelques taches d'une chaine de traitement qu'un data scientist réalise au cotidien: la collection des données, le néttoyage, l'exploration, l'analyse et la fouille en appliquant plusieurs algorithmes de machine learning pour construire des modèles ainsi que la visualisation des résultats obtenus. \n\n**Fournir un projet complet sous spark-notebook pour chacune des bases :  nom.prenom.gz : **"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"5C6D7C613DAC42828D07B481AA9496E6"},"cell_type":"code","source":"//import smile._\n//import smile.io._\nimport java.util.zip.GZIPInputStream\nimport scala.io.Source\nimport smile.util._\nimport smile.math._, Math._\nimport smile.math.distance._\nimport smile.math.kernel._\nimport smile.math.matrix._\nimport smile.stat.distribution._\nimport smile.data._\nimport smile.interpolation._\nimport smile.validation._\nimport smile.association._\nimport smile.regression._\nimport smile.classification._\nimport smile.feature._\nimport smile.clustering._\nimport smile.vq._\nimport smile.manifold._\nimport smile.mds._\nimport smile.sequence._\nimport smile.projection._\nimport smile.nlp._\nimport smile.plot._\nimport java.awt.Color\nimport smile.wavelet._\nimport scala.io.Source\nimport javax.swing.JFrame\nimport javax.swing.JPanel\nimport java.awt.Dimension;\nimport java.awt.Toolkit;\nimport javax.swing.JFrame;\nimport java.awt.GridLayout\nimport javax.swing.JPanel\nimport org.apache.spark.mllib\nimport org.apache.spark.SparkContext\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.mllib.clustering.KMeans\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.util.KMeansDataGenerator\nimport org.apache.spark.mllib.linalg.Matrix\nimport org.apache.spark.mllib.linalg.distributed.RowMatrix\n//import smile.shell._","outputs":[{"name":"stdout","output_type":"stream","text":"import java.util.zip.GZIPInputStream\nimport scala.io.Source\nimport smile.util._\nimport smile.math._\nimport Math._\nimport smile.math.distance._\nimport smile.math.kernel._\nimport smile.math.matrix._\nimport smile.stat.distribution._\nimport smile.data._\nimport smile.interpolation._\nimport smile.validation._\nimport smile.association._\nimport smile.regression._\nimport smile.classification._\nimport smile.feature._\nimport smile.clustering._\nimport smile.vq._\nimport smile.manifold._\nimport smile.mds._\nimport smile.sequence._\nimport smile.projection._\nimport smile.nlp._\nimport smile.plot._\nimport java.awt.Color\nimport smile.wavelet._\nimport scala.io.Source\nimport javax.swing.JFrame\nimport javax.swing.JPanel\nimport java.awt.Dimension\nimport java.awt.Toolkit\nimport javax.swing.JFrame\nimport java.aw..."},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":1}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"4D251CAC57214306A374BCDAB11CCD1D"},"cell_type":"code","source":"import org.apache.spark.rdd.RDD\n\n/*\n * rdd1: the real cluster label\n * rdd2: the predicted cluster label\n *\n */\nclass ExternalIndex(var rdd1:RDD[String],var rdd2:RDD[String]) extends Serializable  {\n  \n  val combinedRDD = rdd1.zip(rdd2)\n//   combinedRDD.cache\n  \n  // Cartesian the combinedRDD with itself so we can use the map function to process on the pair of points\n  val cart = combinedRDD.cartesian(combinedRDD)\n  \n  /*\n   * Take in 2 pair of cluster label and return the yy,ny,nn,yn\n   */\n  private def notation(point1:(String,String),point2:(String,String)) = {\n    if ( (point1._1 == point2._1)  && (point1._2 == point2._2)  ){\n      (\"yy\",1)\n    } else if ( (point1._1 == point2._1)  && (point1._2 != point2._2)  ){\n      (\"yn\",1)\n    } else if ( (point1._1 != point2._1)  && (point1._2 == point2._2)  ){\n      (\"ny\",1)\n    } else {\n      (\"nn\",1)\n    }\n  }\n  \n  /*\n   * Compute the confusion table\n   */\n  def confusionTable()= {\n    this.combinedRDD.map(line => ( line ,1) ).reduceByKey(_+_)\n  }\n  \n  def getNotations() = {\n    val resultNotation = this.cart.map(v => this.notation(v._1,v._2))\n    resultNotation.reduceByKey(_+_)\n  }\n  \n  def purity()= {\n    val table = this.confusionTable\n    val cols = table.map( v => (v._1._2,v))\n    val t = cols.map(v => (v._1,v._2._2))\n    \n    val sum = t.reduceByKey(_+_)\n    val max = t.reduceByKey( (a,b) => if (a>b){a}else{b} )\n    \n    sum.join(max).map(v => v._2).map(a => a._2.toDouble/a._1 ).reduce(_+_)/sum.count\n  }\n  \n  def nmi() = {\n    val num_rows = combinedRDD.count();\n    val t = this.confusionTable\n    \n    val cols = t.map(v => (v._1._2,v._2)).reduceByKey(_+_).collectAsMap\n    val rows = t.map(v => (v._1._1,v._2)).reduceByKey(_+_).collectAsMap\n    println(cols)\n    val rightDenum = t.map(v => (v._1._2,v._2)).reduceByKey(_+_).map(v => cols.get(v._1).get * scala.math.log10((v._2.toDouble)/num_rows)).reduce(_+_);\n    val leftDenum = t.map(v => (v._1._1,v._2)).reduceByKey(_+_).map(v => rows.get(v._1).get * scala.math.log10((v._2.toDouble)/num_rows) ).reduce(_+_)   \n\n    val numerator = -2 * t.map(v => scala.math.log10( ((v._2 * num_rows).toDouble / (rows.get(v._1._1).get * cols.get(v._1._2).get )) )*v._2).reduce(_+_)\n    \n    numerator/(leftDenum + rightDenum)\n  }\n  \n  def precision():Double = {\n    return this.yy.toDouble / (this.yy+this.ny)\n  }\n  def recall():Double = {\n    return (this.yy.toDouble / (this.yy+this.yn))\n  }\n  \n  \n  def yy() = {\n    val notations = this.getNotations\n    if (notations.lookup(\"yy\").length == 0){\n      0.0\n    } else {\n      ((notations.lookup(\"yy\")(0) - combinedRDD.count())/2).toDouble\n    }\n  }\n  \n  def yn() = {\n    val notations = this.getNotations\n    if (notations.lookup(\"yn\").length == 0){\n      0.0\n    } else {\n        ((notations.lookup(\"yn\")(0))/2).toDouble\n    }\n\n  }\n  \n  def ny() = {\n    val notations = this.getNotations\n    if (notations.lookup(\"ny\").length == 0){\n      0.0\n    } else {\n      ((notations.lookup(\"ny\")(0))/2).toDouble\n    }\n  }\n  \n  def nn() = {\n    val notations = this.getNotations\n     if (notations.lookup(\"nn\").length == 0){\n      0.0\n    } else {\n      ((notations.lookup(\"nn\")(0))/2).toDouble\n    }\n  }\n   def nt() = {\n    this.yy + this.yn + this.nn + this.ny\n  }\n  \n  def czekanowskiDice():Double = {\n    return ((2*(this.yy)) / (2* this.yy + this.yn + this.ny ))\n  }\n\n  def rand():Double = {\n    val notations = this.getNotations\n    return ( (this.yy + this.nn) / this.nt )\n  }\n  def rogersTanimoto(): Double = {\n    val denominator = this.yy + (2*(this.yn+this.ny))+this.nn\n    return ((this.yy + this.nn) / denominator)\n  }\n  def folkesMallows():Double = {\n    val denominator = (this.yy+ this.yn)*(this.ny+this.yy)\n    return (this.yy / scala.math.sqrt(denominator))\n  }\n//   def hubert():Double = {\n//     val yy_yn = this.yy + this.yn\n//     val yy_ny = this.yy + this.ny\n//     val nn_yn = this.nn + this.yn\n//     val nn_ny = this.nn + this.ny\n//     val denominator = math.sqrt(yy_yn) * math.sqrt(yy_ny) * math.sqrt(nn_yn) * math.sqrt(nn_ny)\n//     ((this.nt*this.yy) - (yy_yn*yy_ny))/denominator\n//   }\n  def jaccard():Double = {\n    this.yy/(this.yy + this.yn + this.ny)\n  }\n  def kulczynski():Double = {\n    ((this.yy / (this.yy + this.ny)) + (this.yy / (this.yy+this.yn)))/2\n  }\n  def mcNemar():Double = {\n    (((this.nn - this.ny) )/ scala.math.sqrt(this.nn + this.ny))\n  }\n//   def phi():Double = {\n//     val num = (this.yy*this.nn)-(this.yn*this.ny)\n//     val denum = (this.yy + this.yn)*(this.yy + this.ny)*(this.yn + this.nn)*(this.ny + this.nn)\n//     num/denum\n//   }\n  def russelRao():Double = {\n    this.yy / this.nt\n  }\n  def sokalSneath1():Double = {\n    val denum = this.yy + (2*(this.yn + this.ny))\n    this.yy / denum\n  }\n  def sokalSneath2():Double = {\n    val denum = this.yy + this.nn + ((yn + ny)/2)\n    (this.yy + this.nn)/ denum\n  }\n}\n","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.rdd.RDD\ndefined class ExternalIndex\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":2}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"60896A5E3BEA40018C2B2168272BA375"},"cell_type":"code","source":"import org.apache.spark.rdd.RDD\n//import org.apache.spark.SparkContext\n\nclass InternalIndexHelper() extends Serializable{\n  /*\n   * Euclidean Distance\n   * Params:\n   *  point1,point2: Array[Double] - 2 vectors that need to compute the distance\n   * return: Double\n   */\n   def euclidean(point1:Array[Double],point2:Array[Double]) = {\n      val  sum = point1.zip(point2).map(v => scala.math.pow((v._1 - v._2),2)).reduce(_+_)\n      scala.math.sqrt(sum)\n    }\n  \n   /*\n   * Count the number of points in each cluster\n   * Params:\n   *  predict: RDD[String] - the RDD of all cluster labels\n   * return: RDD[(String,Int)] - RDD of tuples of label and the corresponding amount\n   */\n  def clustersSize(predict:RDD[String]) = {\n    predict.map(v => (v,1)).reduceByKey(_+_)\n  }\n  \n  /*\n   * Scatter of point in cluster\n   * Params:\n   *  cluster: RDD[String] - the RDD of cluster that we need to compute\n   * return: Double - Scatter value\n   */\n  def scatter(cluster:RDD[Array[Double]]) = {\n    val centroid = center(cluster)\n    val sumDistance = cluster.map(p => this.euclidean(centroid,p)).reduce(_+_)\n    sumDistance/cluster.count\n  }\n  \n  /*\n   * Centroid of cluster\n   * Params:\n   *  cluster: RDD[String] - the RDD of cluster that we need to compute\n   * return: Array[Double] - The Centroid vector \n   */\n  def center(cluster:RDD[Array[Double]]) = {\n    val dimen = cluster.take(1)(0).length\n    val index = (0 to dimen-1).toArray\n    val numPoints = cluster.count\n    index.map(i => (cluster.map(p => p(i).toDouble).reduce(_+_))/numPoints )\n  }\n  \n  /*\n   * Measure of how good the clustering scheme is\n   * Params:\n   *  scatter1,scatter2: Double - the scatter value of cluster 1 and cluster 2\n   *  center1,center2: Array[Double] - The centroid of cluster 1 and cluster 2\n   */\n  def good(scatter1:Double,scatter2:Double,center1:Array[Double],center2:Array[Double])={\n    val m = this.euclidean(center1,center2)\n    val num = scatter1 + scatter2\n    num/m\n  }\n  /*\n   * Compute the  within-cluster mean distance a(i) for all the point in cluster\n   * Param: cluster: RDD[Array[Double]]\n   * Return index of point and the corresponding a(i) Array[(Long, Double)]\n   */\n  def aiList(cluster:RDD[(Long, Array[Double])]) = {\n    //pair each point with the others in clusters\n    val pointPairs = cluster.cartesian(cluster).filter(v => v._1._1 != v._2._1 )\n    // Compute the distance between each pair\n    val allPointsDistances = pointPairs.map(v => ((v._1._1, v._2._1 ), euclidean(v._1._2,v._2._2)))\n    // Sum all the distances for each point\n    val totalDistanceList = allPointsDistances.map(v => (v._1._1,v._2)).reduceByKey(_+_)\n    // Count the point in cluster\n    val count = totalDistanceList.count\n    // Compute the a{i} list\n    val aiList = totalDistanceList.mapValues(_/(count-1))\n    aiList\n  }\n}\nclass InternalIndex(var point:RDD[Array[Double]],var predict:RDD[String],context:SparkContext){\n  if(predict.count != point.count){\n    throw new Exception(\"the length of predict and points must be the same\")\n  }\n  val clusterLabels = predict.distinct\n  \n  //zip the predict label with the point\n  val combinedRDD = predict.zip(point)\n  val sc = context\n  val internalHelper = new InternalIndexHelper()\n  \n  def scattersList() = {\n    val helper = internalHelper\n    val clusters = this.clusterLabels.collect.map(l => (l,this.combinedRDD.filter(v=> v._1 == l).map(_._2) ) ) \n    val scatters = this.sc.parallelize(clusters.map(x => (x._1,helper.scatter(x._2))))\n    scatters\n  }\n  \n  def centersList() = {\n    val helper = internalHelper\n    val clusters = this.clusterLabels.collect.map(l => (l,this.combinedRDD.filter(v=> v._1 == l).map(_._2) ) ) \n    var centers= this.sc.parallelize(clusters.map(x => (x._1,helper.center(x._2))))\n    centers\n  }\n  \n  \n  /*\n   * Davies Bouldin Index\n   */\n  def davies_bouldin() = {\n    val helper = internalHelper\n    var scatters = this.scattersList()\n    val centers = this.centersList()\n    val clustersWithCenterandScatters = scatters.join(centers)\n    val cart = clustersWithCenterandScatters.cartesian(clustersWithCenterandScatters).filter(v => v._1._1 != v._2._1)\n    val rijList = cart.map(v => ((v._1._1,v._2._1), helper.good(v._1._2._1,v._2._2._1,v._1._2._2,v._2._2._2)))\n    val di = rijList.map(v => (v._1._1,v._2)).reduceByKey((a,b)=> scala.math.max(a,b))\n    val numCluster = clusterLabels.count\n    val davies_bouldin = di.map(v => v._2).reduce(_+_) / numCluster\n    davies_bouldin\n  }\n  /*\n   * The mean of the silhouette widths for a given cluster\n   * Param: label: String - the cluster label that we want to compute\n   * Return Double\n   */\n  def sk(label:String) = {\n    val helper = internalHelper\n    // index all point\n    val indexedData = this.combinedRDD.zipWithIndex().map(v => (v._2,v._1))\n    // get the target cluster\n    val target = indexedData.filter(x => x._2._1==label )\n    // get others cluster\n    val others = indexedData.filter(x => x._2._1!=label )\n    // catersian the target with others\n    val cart = target.cartesian(others)\n    //get the sum distance between each point and other clusters\n    val allDistances = cart.map(x => ((x._1._1,x._2._2._1), helper.euclidean(x._1._2._2,x._2._2._2))).reduceByKey(_+_)\n    // numbers of point of others clusters\n    val numPoints = others.map(x => (x._2._1,1)).reduceByKey(_+_).collectAsMap \n    //mean distance of point to the points of the other clusters \n    val deltas = allDistances.map(x => (x._1._1,x._2/numPoints.get(x._1._2).getOrElse(1)))\n    // Compute b(i) the smallest of these mean distances\n    val bi = deltas.reduceByKey((a,b) => if (a>b) b else a)\n    val ai = helper.aiList(target.map(x => (x._1,x._2._2) ))\n    val si = ai.join(bi).map(x => (x._2._2 - x._2._1)/scala.math.max(x._2._2,x._2._1) )\n    val sk = si.reduce(_+_)/si.count\n    sk\n  }\n  \n  /*\n   * Silhouette Index\n   */\n  def silhouette() = {\n    this.clusterLabels.collect.map(sk).reduce(_+_)/this.clusterLabels.count\n  }\n}","outputs":[{"name":"stdout","output_type":"stream","text":"import org.apache.spark.rdd.RDD\ndefined class InternalIndexHelper\ndefined class InternalIndex\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":3}]},{"metadata":{"id":"5B88356258C94F4D8B190B4D2494D616"},"cell_type":"markdown","source":"\n##**Online News Popularity Data Set** : \nCe jeu de données résume un ensemble hétérogène de caractéristiques sur les articles publiés par Mashable dans une période de deux ans. Le but est de prédire le nombre d'actions dans les réseaux sociaux (popularité).\nhttps://archive.ics.uci.edu/ml/datasets/Online+News+Popularity#\n"},{"metadata":{"id":"809F3CF41B5B46458F72CC98D6CAE1F7"},"cell_type":"markdown","source":"##**Mean-Shift-LSH.zip  *Mean-Shift-PRL.csv.zip**   (obligatoire)\n\nhttps://sites.google.com/site/lebbah/datatp\n\nFig 3    - 4-crescent, n=1000, d=2, fourcres-d2.csv\n         - 4-crescent, n=1000, d=3, fourcres-d3.csv\n         - 4-crescent, n=1000, d=4, fourcres-d4.csv\n         - 4-crescent, n=1000, d=5, fourcres-d5.csv\nFig 4    - type de vegetation n=4771, d=6 covtype.csv\n\nFig 5    - image JPEG 295087.jpg\n         - n=154401, d=5, 295087.csv"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"505F2122E37A435494599BFA82527448"},"cell_type":"markdown","source":"##**KDD-Cup 1999** \nLes données de la base KDD-Cup 1999 ont été préparées et contrôlées par le laboratoire \nMIT Lincoln pour le programme d'évaluation de détection d'intrusion DARPA 1998.\nCes données ont aussi été utilisées pour le concours de détection d'intrusions de KDD 1999.\nChaque connexion est étiquetées en tant que connexion normale ou attaque, avec le type \nspécifique d'attaque. Les attaques trouvées sont classées selon quatre catégories principales :\nDOS (déni de service), R2L (accès non autorisé d'une machine à distance, par exemple devinant\nle mot de passe), U2R (accès non autorisé aux privilèges d'un super-utilisateur tel que \n`buffer overflow`) et `Probe` (sondage et surveillance tel que `port scanning`).\nCes données sont décrites au moyen de différents attributs explicatives. Pour une meilleure\ncompréhension, ceux-ci ont été classifiées en cinq types d'attributs. Les attributs d'une \nmême machine décrivent seulement les connexions faites durant les deux dernières secondes et \nayant le même destinataire que la connexion courante.\nLes attributs de même service décrivent seulement les connexion faites durant les deux \ndernières secondes et ayant le même service que la connexion courante.\nLes attibuts d'une même machine et de même service définissent les critères du trafic de \nconnexion faits en une fenêtre de deux secondes.\nOn trouve aussin des attibuts de connections TCP individuelles. \nEnfin, il existe des attributs indiquent un comportement anormal dans les données, ainsi\nle nombre de tentatives d'ouverture échouées. Il s'agit des attributs de contenu. \n\nPour une description détaillée https://archive.ics.uci.edu/ml/machine-learning-databases/kddcup99-mld/task.html\n\nKDD-Cup'99 : https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data"},{"metadata":{"id":"A02E8C105EAC45E2BF49CA78F7BD48EB"},"cell_type":"markdown","source":"\n# Ce qui est demandé \nLe jeu de données est divisé en deux parites : les données d'apprentissage et les données de test.\nOn va construire nos modèles sur la base de données d'apprentissage ensuite nous allons les évaluer sur les données de test suivant la technique de validation croisée.\n\n* Procéder à un néttoyage de la base si nécessaire\n\n* Lancer plusieurs algorithmes de clustering sur ces données ? \n   utiliser ces algorithmes : \n   * MLIB\n       http://spark.apache.org/docs/latest/mllib-clustering.html\n      * k-means (obligatoire)\n      * Gaussian mixture\n      * power iteration clustering (PIC)\n      * Mean-shift (obligatoire)\n     https://github.com/beckgael/Mean-Shift-LSH\n     \n      * DbScan : https://github.com/alitouka/spark_dbscan   (obligatoire)\n   * Smile \n      * DBScan\n      * CAH,\n      * SOM    (obligatoire)\n      * DENCLUE   (obligatoire)\n      * Spectral Clustering\n     \n   \n* Calculer pour chaque expérimentation les différents indices de qualité internes et externes et tables de confusion (selon la disponibilité du code pour les indices).  \n  * Smile propose quelques indices internes (accuracy, rand)\n  * Sous spark vous pouvez calculer les indices internes et externes en utilisant les codes disponibles sur \n      * https://github.com/Spark-clustering-notebook/ClusteringIndices   (obligatoire)\n      * http://spark.apache.org/docs/latest/mllib-evaluation-metrics.html\n  \n  * Pour avoir une idée sur les indices internes et externes implémentés en spark sur le git, voir le document https://cran.r-project.org/web/packages/clusterCrit/vignettes/clusterCrit.pdf \n \n \n* Visualiser les résultats obtenus pour chacune des approches. Pour les données multi-dimentionnelles vous pouvez utiliser des techniques de projections type PCA, sammon, MDS, ...etc \n\n\n* Quel est le nombre de groupes choisi ? Justifier ce choix ?\n\n\n* Quels algorithmes pensez-vous les mieux adaptés pour ces données ? \n\n\n* Après analyse construisez un système d'aide à la décision en utilisant les arbres de décision, SVM, knn, regression logistic \n\n\n* Construiser deux modèles : un modèle supervisé sur toutes les données et un deuxième modèle en construisant un modèle supervisé pour chaque groupe. Réaliser une validation croisée et calculer les différents indices de qualité\n\n\n* Visualiser les résulats\n\n\n* Appliquer un algorithme de sélection de variables, puis refaite l'apprentissage`. Par exemple l'objet sumSquaresRatio de http://haifengl.github.io/smile/index.html#feature\n\n* Essayer de tester vos codes sur Amazon ...etc \n"},{"metadata":{"id":"F83AC605547045538DE51DD1452060DD"},"cell_type":"markdown","source":"#Chargement des données"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"2F490A9B667C46FFB590F00E6084E3B1"},"cell_type":"code","source":"\n          //val filename = \"file:///home/user9/Data/Mean-Shift-PRL.csv/fourcres-d2.csv\"\n          //val filename = \"file:///home/user9/Data/Mean-Shift-LSH/124084-luv.csv\"\n          val filename = \"file:///home/user9/Data/Mean-Shift-PRL.csv/covtype.csv\"\n          val line = sc.textFile(filename)\n\n          val dataheader = line.map(l => l.split(\",\").map(_.trim))\n          val first = dataheader.first\n          val data = dataheader.filter(_(0) != first(0))\n","outputs":[{"name":"stdout","output_type":"stream","text":"filename: String = file:///home/user9/Data/Mean-Shift-PRL.csv/covtype.csv\nline: org.apache.spark.rdd.RDD[String] = file:///home/user9/Data/Mean-Shift-PRL.csv/covtype.csv MapPartitionsRDD[1] at textFile at <console>:154\ndataheader: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[2] at map at <console>:156\nfirst: Array[String] = Array(\"elevn\", \"aspect\", \"slope\", \"hdist_water\", \"vdist_water\", \"hill_9am\", \"label\")\ndata: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[3] at filter at <console>:158\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":4}]},{"metadata":{"id":"E439E4BA21204DF288C280A307FC562B"},"cell_type":"markdown","source":"# Nettoyage des données KDD (Numériser les variables de type string)"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"0897F08B772E48A981422D8829142D50"},"cell_type":"markdown","source":"\n\n  //to read from gz\n  //def gis(s: String) = new GZIPInputStream(new BufferedInputStream(new FileInputStream(s)))\n\n  //print N lines from a data set\n  def printNlines[T](data: Array[Array[T]], start: Int, end: Int): Unit ={\n    for (i <- start to end - 1) {\n      println(data.toList(i).toList)\n    }\n  }\n\n    val path = \"/home/user9/\"\n    //val path = \"/home/nico/Documents/bigData/machineLearning/MachineLearning/DataTP/KDDCup1999Data/\"\n    val file_name1 = \"kddcup.data_10_percent_corrected\"\n    val file_name2 = \"kddcup.names\"\n    val data_source = scala.io.Source.fromFile(path + file_name1).getLines.filter(!_.isEmpty()).map(_.split(\",\")).toArray\n    //val data_source = Source.fromInputStream(gis(path + file_name1)).getLines.filter(!_.isEmpty()).map(_.split(\",\")).toArray\n    val label_source = scala.io.Source.fromFile(path + file_name2).getLines.drop(1).map(_.split(\":\")(0)).toArray :+ \"label\"\n\n    // 1 - stocker les valeurs des variables non numériques possibles -> toSet\n    val protocol_type_vals = data_source.map(x => x.toList(1)).toSet.toList.sorted\n    val service_vals = data_source.map(x => x.toList(2)).toSet.toList.sorted\n    val flag_vals = data_source.map(x => x.toList(3)).toSet.toList.sorted\n    val label_vals = data_source.map(x => x.toList(41)).toSet.toList.sorted\n    //label_vals.foreach(println)\n\n    // 2 - remplacer ces valeurs par des étiquettes numériques\n    val intIterator = Iterator.from(1)\n    val protocol_type_valsInt = protocol_type_vals.map(x => (x, intIterator.next().toDouble)).toMap\n    val intIterator2 = Iterator.from(1)\n    val service_valsInt = service_vals.map(x => (x,intIterator2.next().toDouble)).toMap\n    val intIterator3 = Iterator.from(1)\n    val flag_valsInt = flag_vals.map(x => (x,intIterator3.next().toDouble)).toMap\n    val intIterator4 = Iterator.from(1)\n    val label_valsInt = label_vals.map(x => (x,intIterator4.next().toDouble)).toMap\n    val data_num = data_source.map(x => Array(x(0).toDouble,protocol_type_valsInt(x(1)), service_valsInt(x(2)), flag_valsInt(x(3)), x(4).toDouble, x(5).toDouble, x(6).toDouble, x(7).toDouble, x(8).toDouble, x(9).toDouble, x(10).toDouble, x(11).toDouble, x(12).toDouble, x(13).toDouble, x(14).toDouble, x(15).toDouble, x(16).toDouble, x(17).toDouble, x(18).toDouble, x(19).toDouble, x(20).toDouble, x(21).toDouble, x(22).toDouble, x(23).toDouble, x(24).toDouble, x(25).toDouble, x(26).toDouble, x(27).toDouble, x(28).toDouble, x(29).toDouble, x(30).toDouble, x(31).toDouble, x(32).toDouble, x(33).toDouble, x(34).toDouble, x(35).toDouble, x(36).toDouble, x(37).toDouble, x(38).toDouble, x(39).toDouble, x(40).toDouble, label_valsInt(x(41)).toDouble ))\n    val data_vect = data_source.map(x => Vectors.dense(x(0).toDouble,protocol_type_valsInt(x(1)), service_valsInt(x(2)), flag_valsInt(x(3)), x(4).toDouble, x(5).toDouble, x(6).toDouble, x(7).toDouble, x(8).toDouble, x(9).toDouble, x(10).toDouble, x(11).toDouble, x(12).toDouble, x(13).toDouble, x(14).toDouble, x(15).toDouble, x(16).toDouble, x(17).toDouble, x(18).toDouble, x(19).toDouble, x(20).toDouble, x(21).toDouble, x(22).toDouble, x(23).toDouble, x(24).toDouble, x(25).toDouble, x(26).toDouble, x(27).toDouble, x(28).toDouble, x(29).toDouble, x(30).toDouble, x(31).toDouble, x(32).toDouble, x(33).toDouble, x(34).toDouble, x(35).toDouble, x(36).toDouble, x(37).toDouble, x(38).toDouble, x(39).toDouble, x(40).toDouble, label_valsInt(x(41)).toDouble ))\n    printNlines(data_source,0, 5)\n    println()\n    printNlines(data_num,0, 5)\n    println(\"\\n***boop***\")\n\n\n\n"},{"metadata":{"presentation":{"tabs_state":"{\n  \"tab_id\": \"#tab791147959-0\"\n}","pivot_chart_state":"{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"},"id":"34890027C0524E569AFBA695EA3560D3"},"cell_type":"markdown","source":"    val dataRDD = sc.parallelize(data_vect)//.slice(0,label_source.size-1))\n    //al dataRDD_Transpose = data_RDD.collect.transpose\n\n\n//label_source.size\n//val labelArray = data_num.map { x => x(label_source.size-1)}\n//label_valsInt\n//data_num.size\n//data_vect.size\ndataRDD.count()"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"856F0AFAC00245C9B7BE2BC69F3DE95E"},"cell_type":"markdown","source":"    val dataRDD = sc.parallelize(data_RDD.slice(0,label_source.size-1))\n    //val dataRDD = sc.parallelize(data_RDD.transpose.slice(0,label_source.size))\n    //val dataRDD_Transpose = dataRDD.collect.toSeq.transpose\n    val labelArray = data_num.map { x => x(label_source.size-1)}\n    val dataArray = data_num.slice(0,label_source.size)"},{"metadata":{"id":"B8119ADF872A418091BE0ED34457206D"},"cell_type":"markdown","source":"#Nettoyage des données : suppression de l'entête / ToDouble / Array variables / Array labels"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"presentation":{"tabs_state":"{\n  \"tab_id\": \"#tab1930722320-0\"\n}","pivot_chart_state":"{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"},"id":"0E4116A2FA5946D39FB53C9449F9587D"},"cell_type":"markdown","source":"val dataheader = line.map(l => l.split(\",\").map(_.trim))\nval first = dataheader.first\nval data = dataheader.filter(_(0) != first(0))\n"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"presentation":{"tabs_state":"{\n  \"tab_id\": \"#tab1094926193-0\"\n}","pivot_chart_state":"{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"},"id":"794FD2E95C4B4AFEBD1D2E15C3623EE1"},"cell_type":"code","source":"val i=6\n//val label = true\n//val dataRDD = data.map { x => Vectors.dense(x.map{y => (y(0).toDouble, y(1).toDouble, y(2).toDouble, y(3).toDouble, y(4).toDouble, y(5).toDouble)})}\n//val dataRDD = data.map { x => Vectors.dense(x(0).toDouble, x(1).toDouble , x(2).toDouble, x(3).toDouble, x(4).toDouble) }\n//val dataArray = data.map { x => Array(x(0).toDouble, x(1).toDouble , x(2).toDouble,  x(3).toDouble, x(4).toDouble) }.collect.toArray\n//val dataArray = data.map { x => x.map { y => (y(0).toDouble, y(1).toDouble, y(2).toDouble, y(3).toDouble, y(4).toDouble, y(5).toDouble)}}.collect.toArray\nval dataRDD = data.map { x => Vectors.dense(x(0).toDouble, x(1).toDouble, x(2).toDouble, x(3).toDouble, x(4).toDouble, x(5).toDouble) }\nval dataArray = data.map { x => Array(x(0).toDouble, x(1).toDouble, x(2).toDouble, x(3).toDouble, x(4).toDouble, x(5).toDouble) }.collect.toArray\nval labelArray = data.map { x => Array(x(i).toDouble) }\nval splitRDD = data.randomSplit(Array(0.7, 0.15, 0.15))\n\n\nvar (trainS, testS, validationS) = (splitRDD(0), splitRDD(1), splitRDD(2))\nvalidationS = validationS.map{ x => Array(x(0), x(1), x(2), x(3), x(4), x(5)) }\n\n\nvalidationS.take(5)\n","outputs":[{"name":"stdout","output_type":"stream","text":"i: Int = 6\ndataRDD: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[35] at map at <console>:176\ndataArray: Array[Array[Double]] = Array(Array(2621.0, 162.0, 13.0, 60.0, -6.0, 232.0), Array(2664.0, 112.0, 5.0, 60.0, -8.0, 229.0), Array(2633.0, 68.0, 8.0, 42.0, 2.0, 228.0), Array(2662.0, 105.0, 5.0, 30.0, -3.0, 228.0), Array(2674.0, 10.0, 8.0, 30.0, 1.0, 211.0), Array(2635.0, 45.0, 8.0, 30.0, 9.0, 223.0), Array(2650.0, 26.0, 19.0, 60.0, 19.0, 208.0), Array(2644.0, 9.0, 32.0, 210.0, 87.0, 168.0), Array(2684.0, 32.0, 20.0, 150.0, 53.0, 211.0), Array(2685.0, 8.0, 10.0, 255.0, 93.0, 208.0), Array(2766.0, 31.0, 7.0, 120.0, 15.0, 218.0), Array(2780.0, 346.0, 13.0, 90.0, 29.0, 195.0), Array(2725.0, 353.0, 19.0, 30.0, 14.0, 183.0), Array(2786.0, 49.0, 16.0, 240.0..."},{"metadata":{},"data":{"text/html":"<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon5ab4047b1505165a7e6001db03be1e0f&quot;,&quot;dataInit&quot;:[{},{},{},{},{}],&quot;genId&quot;:&quot;1094926193&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tabs'], \n      function(playground, _magictabs) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictabs,\n    \"o\": {}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n        <div>\n          <ul class=\"nav nav-tabs\" id=\"ul1094926193\"><li>\n                <a href=\"#tab1094926193-0\"><i class=\"fa fa-table\"/></a>\n              </li><li>\n                <a href=\"#tab1094926193-1\"><i class=\"fa fa-cubes\"/></a>\n              </li></ul>\n\n          <div class=\"tab-content\" id=\"tab1094926193\"><div class=\"tab-pane\" id=\"tab1094926193-0\">\n              <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anonb35b92846c3ec02102c4775e688fa329&quot;,&quot;dataInit&quot;:[{},{},{},{},{}],&quot;genId&quot;:&quot;270369632&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tableChart'], \n      function(playground, _magictableChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictableChart,\n    \"o\": {\"headers\":[],\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n        <p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anonde79a3dc75156933204ae9782993bcc8&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p> <span style=\"color:red\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon706b708b43679cfc743661338d5bcb4f&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p></span>\n        <div>\n        </div>\n      </div></div>\n              </div><div class=\"tab-pane\" id=\"tab1094926193-1\">\n              <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon2c4c411538cd43183de79c174c7a2986&quot;,&quot;dataInit&quot;:[{},{},{},{},{}],&quot;genId&quot;:&quot;1087102539&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/pivotChart'], \n      function(playground, _magicpivotChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magicpivotChart,\n    \"o\": {\"width\":600,\"height\":400,\"derivedAttributes\":{},\"extraOptions\":{}}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n        <p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anona46eac2e4725b66a36c09ac0c8438321&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p> <span style=\"color:red\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anondc173161157d6f66fb67e44d67ce35c4&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p></span>\n        <div>\n        </div>\n      </div></div>\n              </div></div>\n        </div>\n      </div></div>"},"output_type":"execute_result","execution_count":16}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"13F536ED72DA44089430CF2E7A02FC86"},"cell_type":"code","source":"dataRDD.count","outputs":[{"name":"stdout","output_type":"stream","text":"res19: Long = 4771\n"},{"metadata":{},"data":{"text/html":"4771"},"output_type":"execute_result","execution_count":13}]},{"metadata":{"id":"274281E5A5BE47DFA7DD631E75236524"},"cell_type":"markdown","source":"# Plot PCA"},{"metadata":{"id":"AC53B52558AE4D7D8CE390732A70C0CB"},"cell_type":"markdown","source":"val pcamodel = pca(dataArray)\nval pcaCoord = pcamodel.project(dataArray)\n//val pcaCenters = pcamodel.project(centers)\n\n//val win = plot(pcaCoord, // matrice des coordonnées\n//                  labels,  // labels calculés des clusters\n//                  '*', // parametres de visualisations pour chaque cluster\n//                  Palette.rainbow(numClusters) // couleurs des clasters\n                  // valeurs de Palette possibles : topo, terrain, jet, redgreen, redblue, heat, rainbow\n//                 )\n\nval win = smile.plot.plot(pcaCoord, 'S')\n//win.canvas.points(pcaCenters,'O',Color.BLACK)"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"4195656297E14E7FA4AA27E8F7DFFB93"},"cell_type":"code","source":"val mat: RowMatrix = new RowMatrix(dataRDD)\n\n// Compute the top 10 principal components.\nval pc: Matrix = mat.computePrincipalComponents(3) // Principal components are stored in a local dense matrix.\n\n// Project the rows to the linear space spanned by the top 10 principal components.\nval projected = mat.multiply(pc)\n\nval rdd = projected.rows.collect()\nprintln(rdd)\nval ss = rdd.map{x => Array(x(0), x(1), x(2))}\n//val tt = Array(Array(1.9, 2.0), Array(1.9, 2.9))\nval win = smile.plot.plot(ss, 'S')","outputs":[{"name":"stdout","output_type":"stream","text":"[Lorg.apache.spark.mllib.linalg.Vector;@1b3da74f\nmat: org.apache.spark.mllib.linalg.distributed.RowMatrix = org.apache.spark.mllib.linalg.distributed.RowMatrix@2837c0bc\npc: org.apache.spark.mllib.linalg.Matrix = \n-0.8574033588075876    0.5136101086108742      0.03146016179980552     \n-0.03266423890090929   0.008128109047113969    -0.9888041026557154     \n0.002930862959619893   -0.0019681948392771087  -0.0037240769368095984  \n-0.5044521321828694    -0.8416731074903384     0.012727842915055316    \n-0.09647246502681026   -0.16628603539221679    -0.008314582452690497   \n0.002105054003875493   0.008281500204066145    0.14502226750874486     \n-7.851243547582995E-4  0.0012114869313492294   4.976964077483801E-4    \nprojected: org.apache.spark.mllib.linalg.distributed.RowMatrix = org.apache.spark.mllib.linalg.distributed.RowMatrix@43cb3f5e\nrdd..."},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":6}]},{"metadata":{"id":"E2983B09D5DB481A86C4F07D45A26E77"},"cell_type":"markdown","source":"#MLlib : Kmeans"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"0C30B0BD46F845D18715421DA66DA12B"},"cell_type":"code","source":"val numClusters = 5\nval nbIterations = 200","outputs":[{"name":"stdout","output_type":"stream","text":"numClusters: Int = 5\nnbIterations: Int = 200\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":69}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"presentation":{"tabs_state":"{\n  \"tab_id\": \"#tab120106278-0\"\n}","pivot_chart_state":"{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"},"id":"313E497F610B49449BF1B83F9A5DCE60"},"cell_type":"code","source":"testDataK.take(5)\n//dataRDD.take(5)\n//val temp = numClusters.map(x =>  org.apache.spark.mllib.clustering.KMeans.train(dataRDD,x, nbIterations))\n//val coord = temp.map(x => x.predict(dataRDD).collect(), x.predict(dataRDD))\n//coord.map(x => new InternalIndex(dataRDD.map(_.toArray),labels_kmeansRDD.map(_.toString),sc))","outputs":[{"name":"stdout","output_type":"stream","text":"res54: Array[org.apache.spark.mllib.linalg.Vector] = Array([2644.0,9.0,32.0,210.0,87.0,168.0,2.0], [2684.0,32.0,20.0,150.0,53.0,211.0,2.0], [2868.0,332.0,17.0,60.0,23.0,177.0,2.0], [2566.0,326.0,11.0,256.0,87.0,193.0,5.0], [2902.0,54.0,23.0,391.0,120.0,227.0,2.0])\n"},{"metadata":{},"data":{"text/html":"<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anondf764ba46c5d0f910f18031938a3dd4c&quot;,&quot;dataInit&quot;:[{&quot;values&quot;:&quot;[D@62ba61fc&quot;},{&quot;values&quot;:&quot;[D@7e2512ce&quot;},{&quot;values&quot;:&quot;[D@c2fbee4&quot;},{&quot;values&quot;:&quot;[D@6b51f3ad&quot;},{&quot;values&quot;:&quot;[D@5a55daba&quot;}],&quot;genId&quot;:&quot;120106278&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tabs'], \n      function(playground, _magictabs) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictabs,\n    \"o\": {}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n        <div>\n          <ul class=\"nav nav-tabs\" id=\"ul120106278\"><li>\n                <a href=\"#tab120106278-0\"><i class=\"fa fa-table\"/></a>\n              </li><li>\n                <a href=\"#tab120106278-1\"><i class=\"fa fa-cubes\"/></a>\n              </li></ul>\n\n          <div class=\"tab-content\" id=\"tab120106278\"><div class=\"tab-pane\" id=\"tab120106278-0\">\n              <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anoncccaf70fd26f1eb0d3ef759502a6ae18&quot;,&quot;dataInit&quot;:[{&quot;values&quot;:&quot;[D@62ba61fc&quot;},{&quot;values&quot;:&quot;[D@7e2512ce&quot;},{&quot;values&quot;:&quot;[D@c2fbee4&quot;},{&quot;values&quot;:&quot;[D@6b51f3ad&quot;},{&quot;values&quot;:&quot;[D@5a55daba&quot;}],&quot;genId&quot;:&quot;892097699&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tableChart'], \n      function(playground, _magictableChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictableChart,\n    \"o\": {\"headers\":[\"values\"],\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n        <p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon88a5525b29f9f5327c074480a4a7cf50&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p> <span style=\"color:red\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon6d7dcb9eeb61fea110ef90496cc0e5ce&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p></span>\n        <div>\n        </div>\n      </div></div>\n              </div><div class=\"tab-pane\" id=\"tab120106278-1\">\n              <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon856a17cb253e2371180c9b54d5509051&quot;,&quot;dataInit&quot;:[{&quot;values&quot;:&quot;[D@62ba61fc&quot;},{&quot;values&quot;:&quot;[D@7e2512ce&quot;},{&quot;values&quot;:&quot;[D@c2fbee4&quot;},{&quot;values&quot;:&quot;[D@6b51f3ad&quot;},{&quot;values&quot;:&quot;[D@5a55daba&quot;}],&quot;genId&quot;:&quot;745776995&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/pivotChart'], \n      function(playground, _magicpivotChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magicpivotChart,\n    \"o\": {\"width\":600,\"height\":400,\"derivedAttributes\":{},\"extraOptions\":{}}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n        <p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon515b25566e6aad3a5f8e30fde392ad80&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p> <span style=\"color:red\"><p data-bind=\"text: value\"><script data-this=\"{&quot;valueId&quot;:&quot;anon213f18d03633894bd8ac15861ee1368f&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId)\n    },\n    this\n  );\n});\n        /*]]>*/</script></p></span>\n        <div>\n        </div>\n      </div></div>\n              </div></div>\n        </div>\n      </div></div>"},"output_type":"execute_result","execution_count":34}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"1F79C09FC36D4F658D01550FF889AB87"},"cell_type":"code","source":"\nval clusters_kmeans = org.apache.spark.mllib.clustering.KMeans.train(dataRDD, numClusters, nbIterations)\n","outputs":[{"name":"stdout","output_type":"stream","text":"clusters_kmeans: org.apache.spark.mllib.clustering.KMeansModel = org.apache.spark.mllib.clustering.KMeansModel@32b73405\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":70}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"117BFF4F0E474E49A21A55ED1D19DDB3"},"cell_type":"code","source":"val labels_kmeans = clusters_kmeans.predict(dataRDD).collect()\nval labels_kmeansRDD = clusters_kmeans.predict(dataRDD)\nval centers = clusters_kmeans.clusterCenters.map( x => x.toArray)\n//val win = plot(dataArray, // matrice des coordonnées\n//                  labels_kmeans,  // labels calculés des clusters\n//                  '#', // parametres de visualisations pour chaque claster\n//                  Palette.rainbow(numClusters) // couleurs des clusters\n                  // valeurs de Palette possibles : topo, terrain, jet, redgreen, redblue, heat, rainbow\n//                 )\n//smile.plot.ScatterPlot.plot(centers,'O', Color.BLACK)\n//              win.canvas.points(centers,'*',Color.BLACK)\nval mat: RowMatrix = new RowMatrix(dataRDD)\n\n// Compute the top 10 principal components.\nval pc: Matrix = mat.computePrincipalComponents(3) // Principal components are stored in a local dense matrix.\n\n// Project the rows to the linear space spanned by the top 10 principal components.\nval projected = mat.multiply(pc)\n\nval rdd = projected.rows.collect()\nprintln(rdd)\nval ss = rdd.map{x => Array(x(0), x(1), x(2))}\n//val tt = Array(Array(1.9, 2.0), Array(1.9, 2.9))\nval win = smile.plot.plot(ss, labels_kmeans, '#',Palette.rainbow(numClusters))","outputs":[{"name":"stdout","output_type":"stream","text":"[Lorg.apache.spark.mllib.linalg.Vector;@59b64469\nlabels_kmeans: Array[Int] = Array(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 1, 1, 1, 1, 3, 1, 1, 1, 3, 3, 4, 3, 1, 3, 4, 1, 3, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 3, 1, 1, 3, 1, 3, 3, 3, 3, 3, 1, 3, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 3, 1, 1, 3, 1, 3, 3, 1, 1, 1, 3, 1, 1, 4, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 4, 1, 3, 3, 1, 1, 3, 1, 1, 1, 1, 4, 3, 3, 3, 1, 1, 3, 4, 1, 1, 4, 3, 3, 1, 1, 3, 4, 1, 1, 1, 1, 1, 4, 3, 1, 1, 1, 3, 4, 1, 1, 1, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 1, 1, 1, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 1, 1, 4, 4, 4, 3, 3, 3, 1, 4, 4, 1, 1, 4, 4, 4, 4, 4, 4, 4, 1, 1, 4, 4, 4, 4, 3, 1, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 3..."},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":72}]},{"metadata":{"id":"253552C1649843D8B96F7129132C15D3"},"cell_type":"markdown","source":"<img src=\"http://i.imgur.com/nhSDD9d.jpg\" alt=\"kmeans\" height=\"1000\" width=\"1000\">"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"0CA4B5212E5346D59DACB63A01D38D01"},"cell_type":"code","source":"val id_kmean = new InternalIndex(dataRDD.map(_.toArray),labels_kmeansRDD.map(_.toString),sc)\nprintln(\"Davies Bouldin Index \" + id_kmean.davies_bouldin())  // \nprintln(\"Silhouette Index \" + id_kmean.silhouette())\n","outputs":[{"name":"stdout","output_type":"stream","text":"Davies Bouldin Index 1.171322559616296\nSilhouette Index 0.30006217874130714\nid_kmean: InternalIndex = $iwC$$iwC$$iwC$InternalIndex@55f33a2c\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":18}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"D859ADA9105F41628072D63C81533F00"},"cell_type":"code","source":"val id_kmean2 = new ExternalIndex(data.map(_.toString),labels_kmeansRDD.map(_.toString))\n\nprintln(\"czekanowskiDice=\"+id_kmean2.czekanowskiDice)\nprintln(\"rand=\"+id_kmean2.rand)\nprintln(\"rogersTanimoto=\"+id_kmean2.rogersTanimoto)\nprintln(\"folkesMallows=\"+id_kmean2.folkesMallows)\nprintln(\"jaccard=\"+id_kmean2.jaccard)\nprintln(\"kulczynski=\"+id_kmean2.kulczynski)\nprintln(\"mcNemar=\"+id_kmean2.mcNemar)\nprintln(\"russelRao=\"+id_kmean2.russelRao)\nprintln(\"sokalSneath1=\"+id_kmean2.sokalSneath1)\nprintln(\"sokalSneath2=\"+id_kmean2.sokalSneath2)\nprintln(\"recall=\"+id_kmean2.recall)\nprintln(\"precision=\"+id_kmean2.precision)\nprintln(\"czekanowskiDice=\"+id_kmean2.czekanowskiDice)\nprintln(\"rand=\"+id_kmean2.rand)\nprintln(\"rogersTanimoto=\"+id_kmean2.rogersTanimoto)\nprintln(\"folkesMallows=\"+id_kmean2.folkesMallows)\nprintln(\"jaccard=\"+id_kmean2.jaccard)\nprintln(\"kulczynski=\"+id_kmean2.kulczynski)\nprintln(\"mcNemar=\"+id_kmean2.mcNemar)\nprintln(\"russelRao=\"+id_kmean2.russelRao)\nprintln(\"sokalSneath1=\"+id_kmean2.sokalSneath1)\nprintln(\"sokalSneath2=\"+id_kmean2.sokalSneath2)\nprintln(\"recall=\"+id_kmean2.recall)\nprintln(\"precision=\"+id_kmean2.precision)","outputs":[{"name":"stdout","output_type":"stream","text":"czekanowskiDice=0.0\n"}]},{"metadata":{"id":"F32F47659C94461A9A55E1C34235023A"},"cell_type":"markdown","source":"#MLlib : Gaussian Mixture"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"95EE1C6C3CB840C4A270725B4AB3F77F"},"cell_type":"code","source":"import org.apache.spark.mllib.clustering.{GaussianMixture, GaussianMixtureModel}\nimport org.apache.spark.mllib.linalg.Vectors\n\n// Load and parse the data\n//val featuresData = data.map{x => Vectors.dense(x(0).toDouble, x(1).toDouble, x(2).toDouble, x(3).toDouble, x(4).toDouble)}\n\n// Cluster the data into two classes using GaussianMixture\nval gmm = new GaussianMixture().setK(7).run(dataRDD)\n\n// output parameters of max-likelihood model\nfor (i <- 0 until gmm.k) {\n  println(\"weight=%f\\nmu=%s\\nsigma=\\n%s\\n\" format\n    (gmm.weights(i), gmm.gaussians(i).mu, gmm.gaussians(i).sigma))\n}","outputs":[{"name":"stdout","output_type":"stream","text":"weight=0,075273\nmu=[2972.6443940247036,166.35551617191632,17.806957118275342,390.1477196229197,83.8480662243756,207.44550301229785]\nsigma=\n108882.48872319244  1229.2202710412976   -688.1499472098882  ... (6 total)\n1229.2202710412976  12705.368300261403   36.634187370221326  ...\n-688.1499472098882  36.634187370221326   67.08915747376342   ...\n47042.91794457778   1724.1455081820056   -815.2125833165003  ...\n9253.06970332358    434.4530960529948    24.35119064675152   ...\n880.183870018461    -1954.3185712818279  -56.2596786933846   ...\n\nweight=0,074844\nmu=[2973.282389628098,165.97019393767442,17.801705786383504,390.65544662490277,83.94011011368161,207.5260629306937]\nsigma=\n108992.6660598207   1249.9718471055019  -686.2826406831454  ... (6 total)\n1249.9718471055019  12705.706864819002  36.43836024312436   ...\n-686.2826406831454  36.43836024312436   67.22952100414517   ...\n47034.09985063346   1762.1721819497407  -815.5064896855093  ...\n9273.10152887124    442.462944368284    24.622761132955716  ...\n869.1866272285706   -1947.819243181736  -55.97322169701307  ...\n\nweight=0,074695\nmu=[2973.4858976050496,165.91346269262874,17.80129102410522,390.80619437502406,83.97051877310945,207.53273996807025]\nsigma=\n109033.65524837538  1249.8721137151376  -686.006665386939   ... (6 total)\n1249.8721137151376  12708.839300112137  36.418253402688464  ...\n-686.006665386939   36.418253402688464  67.274563153017     ...\n47042.17819772491   1768.2551751554884  -815.7239302246742  ...\n9280.47791634192    443.7309703268833   24.653510989327067  ...\n868.8453494668662   -1946.989316778035  -55.95926417857268  ...\n\nweight=0,074698\nmu=[2973.481847948405,165.91687981902479,17.80127003514058,390.80299806183535,83.96957388600235,207.53185765902614]\nsigma=\n109032.74803645714  1249.7353617979481  -686.02146518138    ... (6 total)\n1249.7353617979481  12708.925143185885  36.42182461333185   ...\n-686.02146518138    36.42182461333185   67.27328271514257   ...\n47042.3411429199    1767.933370619623   -815.7195862101703  ...\n9280.31096834176    443.67130748062675  24.651521580452837  ...\n868.9600299678133   -1947.042975624418  -55.96302000076858  ...\n\nweight=0,550979\nmu=[2886.164028619233,156.36313427816606,13.369382439381633,188.8308671097437,34.38069390911598,215.81670432740768]\nsigma=\n90731.52455555381    4462.142019078127   -248.61275825988275  ... (6 total)\n4462.142019078127    10926.144773303755  -4.158905686270115   ...\n-248.61275825988275  -4.158905686270115  35.370964310810535   ...\n17098.28795708642    573.5331915417618   14.627223666767534   ...\n2415.617966938813    136.06701138678756  67.98845732844342    ...\n-372.5357915117753   -1355.613489415067  -13.32827927872689   ...\n\nweight=0,074715\nmu=[2973.4579148277385,165.90600285691647,17.801189615431188,390.78765290444386,83.9667163969877,207.53609199110807]\nsigma=\n109027.4401077852   1251.1004857187806   -685.975519289786   ... (6 total)\n1251.1004857187806  12707.711261477954   36.4126873152827    ...\n-685.975519289786   36.4126873152827     67.2691887037281    ...\n47038.80162791402   1768.6979420662637   -815.6740593004141  ...\n9279.39054739927    443.8354952627575    24.660790374072384  ...\n868.2281266364357   -1946.8344894118438  -55.94371105115399  ...\n\nweight=0,074796\nmu=[2973.342855451135,165.93995407504096,17.801724767695728,390.70137600158125,83.95096619819829,207.53244591528684]\nsigma=\n109005.1564332103   1250.8170442842697   -686.1464311668975  ... (6 total)\n1250.8170442842697  12705.768813560378   36.413794388104606  ...\n-686.1464311668975  36.413794388104606   67.2448984699461    ...\n47034.53560207679   1765.1744179289453   -815.5694396426524  ...\n9275.364513494445   443.04466547387705   24.640178071728474  ...\n868.4444733795117   -1947.3516046649738  -55.94869472852061  ...\n\nimport org.apache.spark.mllib.clustering.{GaussianMixture, GaussianMixtureModel}\nimport org.apache.spark.mllib.linalg.Vectors\ngmm: org.apache.spark.mllib.clustering.GaussianMixtureModel = org.apache.spark.mllib.clustering.GaussianMixtureModel@3fd55c4e\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":85}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"C5366586F25C4779817E105F60F5DF44"},"cell_type":"code","source":"val labels_gm = gmm.predict(dataRDD).collect()\nval labels_gmRDD = gmm.predict(dataRDD)\nval centers = clusters_kmeans.clusterCenters.map( x => x.toArray)\n//val win = plot(dataArray, // matrice des coordonnées\n//                  labels_kmeans,  // labels calculés des clusters\n//                  '#', // parametres de visualisations pour chaque claster\n//                  Palette.rainbow(numClusters) // couleurs des clusters\n                  // valeurs de Palette possibles : topo, terrain, jet, redgreen, redblue, heat, rainbow\n//                 )\n//smile.plot.ScatterPlot.plot(centers,'O', Color.BLACK)\n//              win.canvas.points(centers,'*',Color.BLACK)\nval mat: RowMatrix = new RowMatrix(dataRDD)\n\n// Compute the top 10 principal components.\nval pc: Matrix = mat.computePrincipalComponents(3) // Principal components are stored in a local dense matrix.\n\n// Project the rows to the linear space spanned by the top 10 principal components.\nval projected = mat.multiply(pc)\n\nval rdd = projected.rows.collect()\nprintln(rdd)\nval ss = rdd.map{x => Array(x(0), x(1), x(2))}\n//val tt = Array(Array(1.9, 2.0), Array(1.9, 2.9))\nval win = smile.plot.plot(ss, labels_gm, '#',Palette.rainbow(numClusters))","outputs":[{"name":"stdout","output_type":"stream","text":"[Lorg.apache.spark.mllib.linalg.Vector;@1e387a0f\njava.lang.IllegalArgumentException: Too few colors.\n\tat smile.plot.ScatterPlot.<init>(ScatterPlot.java:177)\n\tat smile.plot.ScatterPlot.<init>(ScatterPlot.java:144)\n\tat smile.plot.ScatterPlot.plot(ScatterPlot.java:521)\n\tat smile.plot.ScatterPlot.plot(ScatterPlot.java:484)\n\tat smile.plot.Operators$class.plot(Operators.scala:85)\n\tat smile.plot.package$.plot(package.scala:23)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:230)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:246)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:248)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:250)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:252)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:254)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:256)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:258)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:260)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:262)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:264)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:266)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:268)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:270)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:272)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:274)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:276)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:278)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:280)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:282)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:284)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:286)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:288)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:290)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:292)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:294)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:296)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:298)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:300)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:302)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:304)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:306)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:308)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:310)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:312)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:314)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:316)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:318)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:320)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:322)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:324)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:326)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:328)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:330)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:332)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:334)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:336)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:338)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:340)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:342)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:344)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:346)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:348)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:350)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:352)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:354)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:356)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:358)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:360)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:362)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:364)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:366)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:368)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:370)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:372)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:374)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:376)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:378)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:380)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:382)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:384)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:386)\n\tat $iwC$$iwC$$iwC$$iwC.<init>(<console>:388)\n\tat $iwC$$iwC$$iwC.<init>(<console>:390)\n\tat $iwC$$iwC.<init>(<console>:392)\n\tat $iwC.<init>(<console>:394)\n\tat <init>(<console>:396)\n\tat .<init>(<console>:400)\n\tat .<clinit>(<console>)\n\tat .<init>(<console>:7)\n\tat .<clinit>(<console>)\n\tat $print(<console>)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n\tat notebook.kernel.Repl$$anonfun$6.apply(Repl.scala:200)\n\tat notebook.kernel.Repl$$anonfun$6.apply(Repl.scala:200)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat scala.Console$.withOut(Console.scala:126)\n\tat notebook.kernel.Repl.evaluate(Repl.scala:199)\n\tat notebook.client.ReplCalculator$$anonfun$10$$anon$1$$anonfun$27.replEvaluate$1(ReplCalculator.scala:401)\n\tat notebook.client.ReplCalculator$$anonfun$10$$anon$1$$anonfun$27.apply(ReplCalculator.scala:414)\n\tat notebook.client.ReplCalculator$$anonfun$10$$anon$1$$anonfun$27.apply(ReplCalculator.scala:395)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)\n\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\n\n"}]},{"metadata":{"id":"C41E11E5BF374CCB82B36B90C4DE0250"},"cell_type":"markdown","source":"<img src=\"http://i.imgur.com/S6O8Dus.jpg\" alt=\"gm\" height=\"1000\" width=\"1000\">"},{"metadata":{"id":"52BF601DAD8B4E0B95EF5227130FAE7E"},"cell_type":"markdown","source":""},{"metadata":{"id":"1D7EC7A72C024EB2A9D734F3480C4893"},"cell_type":"markdown","source":"#MLlib : PIC"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"D4EC3A95174646F2A905285360CCEA88"},"cell_type":"markdown","source":"    import org.apache.spark.mllib.clustering.PowerIterationClustering\n    // pairwise similarities\n    val similarities: RDD[(Long, Long, Double)] = sc.paralellize\n    val pic = new PowerIteartionClustering()\n      .setK(3)\n      .setMaxIterations(20)\n    val model = pic.run(similarities)\n    model.assignments.collect().foreach { a =>\n      println(s\"${a.id} -> ${a.cluster}\")\n    }"},{"metadata":{"id":"861C3193AAAE4780865FD2A2B2EF23F9"},"cell_type":"markdown","source":"#Kmeans SMILE"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"7B992515482C403D809C5398708B7790"},"cell_type":"code","source":"val nbRun = 30\nval clusterskm = smile.clustering.kmeans(dataArray, 4, nbIterations, nbRun)\nval clkm = clusterskm.getClusterLabel \nval framenkm = new JFrame(\"kmeans\");\n\t\t\t\t\tframenkm.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n\t\t\t\t\tframenkm.setLocationRelativeTo(null);\n\t\t\t\t\tframenkm.setVisible(true);\n\t\t\t\t\tframenkm.setLayout(new GridLayout(1, 1))\n\t\t\t\t\tframenkm.setSize(800,800)\nval canvaskm = ScatterPlot.plot(dataArray, clkm, '#', Palette.COLORS)\nframenkm.add(canvaskm);\n\n\t\t\t\t\t\t\t\t\tframenkm.getContentPane().add(canvaskm);","outputs":[{"name":"stdout","output_type":"stream","text":"<console>:150: error: not found: value dataArray\n              val clusterskm = smile.clustering.kmeans(dataArray, 4, nbIterations, nbRun)\n                                                       ^\n<console>:158: error: not found: value dataArray\n              val canvaskm = ScatterPlot.plot(dataArray, clkm, '#', Palette.COLORS)\n                                              ^\n"}]},{"metadata":{"id":"8388964A9294440A9F267BA90709468E"},"cell_type":"markdown","source":"#SMILE : DENCLUE"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"B1615B40CBEB42DEAB59B82B210EACF2"},"cell_type":"code","source":"val clusters = smile.clustering.denclue(dataArray, 0.5, 20)\nval cl = clusters.getClusterLabel\n//val plot = smile.plot.plot(clusters, cl, '#', Palette.COLORS)\n/*val framen = new JFrame(\"DENCLUE\");\nframen.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\nframen.setLocationRelativeTo(null);\nframen.setVisible(true);\nframen.setLayout(new GridLayout(1, 1))\nframen.setSize(800,800)\nval canvas = ScatterPlot.plot(dataArray, cl, '#', Palette.COLORS)\nframen.add(canvas);\nframen.getContentPane().add(canvas);*/\n\n\nval mat: RowMatrix = new RowMatrix(dataRDD)\n\n// Compute the top 10 principal components.\nval pc: Matrix = mat.computePrincipalComponents(3) // Principal components are stored in a local dense matrix.\n\n// Project the rows to the linear space spanned by the top 10 principal components.\nval projected = mat.multiply(pc)\n\nval rdd = projected.rows.collect()\nprintln(rdd)\nval ss = rdd.map{x => Array(x(0), x(1), x(2))}\n//val tt = Array(Array(1.9, 2.0), Array(1.9, 2.9))\nval win = smile.plot.plot(ss, cl, '#',Palette.rainbow(cl.size))\n","outputs":[{"name":"stdout","output_type":"stream","text":"[Lorg.apache.spark.mllib.linalg.Vector;@106d9bbc\nclusters: smile.clustering.DENCLUE = \nDENCLUE clusters of 4771 data points:\n  0\t    1 ( 0.0%)\n  1\t    1 ( 0.0%)\n  2\t    1 ( 0.0%)\n  3\t    1 ( 0.0%)\n  4\t    1 ( 0.0%)\n  5\t    1 ( 0.0%)\n  6\t    1 ( 0.0%)\n  7\t    1 ( 0.0%)\n  8\t    1 ( 0.0%)\n  9\t    1 ( 0.0%)\n 10\t    1 ( 0.0%)\n 11\t    1 ( 0.0%)\n 12\t    1 ( 0.0%)\n 13\t    1 ( 0.0%)\n 14\t    1 ( 0.0%)\n 15\t    1 ( 0.0%)\n 16\t    1 ( 0.0%)\n 17\t    1 ( 0.0%)\n 18\t    1 ( 0.0%)\n 19\t    1 ( 0.0%)\n 20\t    1 ( 0.0%)\n 21\t    1 ( 0.0%)\n 22\t    1 ( 0.0%)\n 23\t    1 ( 0.0%)\n 24\t    1 ( 0.0%)\n 25\t    1 ( 0.0%)\n 26\t    1 ( 0.0%)\n 27\t    1 ( 0.0%)\n 28\t    1 ( 0.0%)\n 29\t    1 ( 0.0%)\n 30\t    1 ( 0.0%)\n 31\t    1 ( 0.0%)\n 32\t    1 ( 0.0%)\n 33\t    1 ( 0.0%)\n 34\t    1 ( 0.0%)\n 35\t    1 ( 0.0%)\n 36\t    1 ( 0.0%)\n 37\t    1 ( 0.0%)\n 38\t    1 ( 0.0%)\n 39\t    1 ( 0.0%)\n ..."},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":7}]},{"metadata":{"id":"191D320389FF4F9E80CDBC7508ABA738"},"cell_type":"markdown","source":"<img src=\"http:i.imgur.com/R9pmfQF.jpg\" alt=\"kmeans\" height=\"1000\" width=\"1000\">"},{"metadata":{"id":"95A82CC6F50F4F8D826BDDE79A08E2B4"},"cell_type":"markdown","source":"<img src=\"http://imgur.com/R9pmfQF\" alt=\"kmeans\" height=\"1000\" width=\"1000\">"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"53CA19936FC4469D8764CDA604F6D8BB"},"cell_type":"markdown","source":"#SMILE : SOM"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"A1E605AF617742AEBDA22F71F0D67BE8"},"cell_type":"code","source":"\nval clustersom = smile.vq.som(dataArray,4,4)\nval indice= dataArray.map{x=>clustersom.predict(x)}\n\n/*\nval framenom = new JFrame(\"SOM\");\nframenom.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\nframenom.setLocationRelativeTo(null);\nframenom.setVisible(true);\nframenom.setLayout(new GridLayout(1, 1))\nframenom.setSize(800,800)\nval canvasom = ScatterPlot.plot(dataArray, indice, '#', Palette.COLORS)\nframenom.add(canvasom);\nframenom.getContentPane().add(canvasom)*/\n\n\n\nval mat: RowMatrix = new RowMatrix(dataRDD)\n\n// Compute the top 10 principal components.\nval pc: Matrix = mat.computePrincipalComponents(3) // Principal components are stored in a local dense matrix.\n\n// Project the rows to the linear space spanned by the top 10 principal components.\nval projected = mat.multiply(pc)\n\nval rdd = projected.rows.collect()\nprintln(rdd)\nval ss = rdd.map{x => Array(x(0), x(1), x(2))}\n//val tt = Array(Array(1.9, 2.0), Array(1.9, 2.9))\nval win = smile.plot.plot(ss, indice, '#',Palette.COLORS)","outputs":[{"name":"stdout","output_type":"stream","text":"[Lorg.apache.spark.mllib.linalg.Vector;@4567d297\nclustersom: smile.vq.SOM = smile.vq.SOM@250ea162\nindice: Array[Int] = Array(1, 1, 1, 1, 1, 1, 1, 0, 1, 4, 2, 3, 2, 5, 5, 8, 5, 3, 3, 12, 0, 0, 0, 0, 12, 1, 4, 0, 8, 8, 3, 9, 0, 9, 10, 0, 9, 0, 0, 0, 0, 12, 9, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 6, 0, 0, 6, 0, 0, 0, 0, 0, 0, 5, 0, 4, 4, 0, 8, 1, 1, 4, 0, 12, 9, 8, 9, 5, 1, 4, 0, 0, 1, 1, 4, 0, 12, 8, 1, 0, 1, 1, 4, 0, 0, 8, 4, 4, 8, 0, 0, 0, 8, 0, 1, 7, 1, 1, 4, 1, 8, 0, 1, 1, 1, 8, 1, 2, 1, 4, 8, 1, 1, 4, 1, 1, 1, 1, 3, 5, 5, 8, 0, 1, 4, 3, 0, 1, 4, 4, 4, 1, 1, 8, 1, 1, 1, 1, 1, 1, 7, 8, 1, 1, 1, 5, 6, 1, 1, 1, 2, 1, 2, 6, 6, 4, 1, 2, 5, 1, 0, 1, 1, 2, 3, 1, 2, 2, 2, 3, 3, 3, 7, 4, 5, 2, 1, 2, 3, 5, 3, 3, 3, 6, 5, 2, 2, 3, 1, 1, 2, 3, 6, 8, 5, 5, 1, 5, 3, 1, 2, 2, 3, 3, 2, 3, 3, 3, 1, 1, 2, 2, 3, 2, 5, 2, 3, 3, 3, 3, 5, 2, 3, 1, 1, 1, 2, 2, 2..."},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":12}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"C38F6A2DA1054283ADEC514D1A4AB1F4"},"cell_type":"markdown","source":"#Données 3D"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"41ACEC91891D4CB986A259C13CA5B3DA"},"cell_type":"markdown","source":"val filename = \"file:///home/user9/Data/Mean-Shift-PRL.csv/fourcres-d3.csv\"\nval line3D = sc.textFile(filename)\nval dataheader3D = line3D.map(l => l.split(\",\").map(_.trim))\nval first = dataheader3D.first\nval data3D = dataheader3D.filter(_(0) != first(0))\nval dataRDD3D = data3D.map { x => Vectors.dense(x(0).toDouble, x(1).toDouble, x(2).toDouble) }\nval dataArray3D = data3D.map { x => Array(x(0).toDouble, x(1).toDouble , x(2).toDouble) }.collect.toArray\nval labelArray3D = data3D.map { x => Array(x(3).toDouble) }"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"1BF652F87DAC48C288D555949AA2E27F"},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"74671C25A1974FB0984D0176DDAE4C60"},"cell_type":"code","source":"import org.apache.spark.mllib.tree.DecisionTree\nimport org.apache.spark.mllib.tree.model.DecisionTreeModel\nimport org.apache.spark.mllib.util.MLUtils\nimport org.apache.spark.mllib.regression.LabeledPoint \n\n// Load and parse the data file.\n\nval filename1 = \"file:///home/user9/Data/Mean-Shift-PRL.csv/fourcres-d5.csv\"\n          val line1 = sc.textFile(filename1)\n\n          val dataheader1 = line1.map(l => l.split(\",\").map(_.trim))\n          val first1 = dataheader1.first\n          val data1 = dataheader1.filter(_(0) != first1(0))\n\n// Split the data into training and test sets (30% held out for testing)\nval labeledData = data1.map{x => LabeledPoint(x(5).toDouble, Vectors.dense(x(0).toDouble, x(1).toDouble, x(2).toDouble, x(3).toDouble, x(4).toDouble))}\nval splits = labeledData.randomSplit(Array(0.7, 0.3))\nval (trainingData, testData) = (splits(0), splits(1))\n\n// Train a DecisionTree model.\n//  Empty categoricalFeaturesInfo indicates all features are continuous.\nval numClasses = 5\nval categoricalFeaturesInfo = Map[Int, Int]()\nval impurity = \"gini\"\nval maxDepth = 5\nval maxBins = 32\n\nval model = DecisionTree.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo,\n  impurity, maxDepth, maxBins)\n\n// Evaluate model on test instances and compute test error\nval labelAndPreds = testData.map { point =>\n  val prediction = model.predict(point.features)\n  (point.label, prediction)\n}\n\nlabelAndPreds.take(5)\nval testErr = labelAndPreds.filter(r => r._1 != r._2).count().toDouble / testData.count()\nprintln(\"Test Error = \" + testErr)\nprintln(\"Learned classification tree model:\\n\" + model.toDebugString)\n\n","outputs":[{"name":"stdout","output_type":"stream","text":"Test Error = 0.003205128205128205\nLearned classification tree model:\nDecisionTreeModel classifier of depth 5 with 19 nodes\n  If (feature 4 <= -0.334642511215876)\n   If (feature 3 <= 0.449914673599503)\n    Predict: 2.0\n   Else (feature 3 > 0.449914673599503)\n    If (feature 4 <= -1.02893865416534)\n     If (feature 3 <= 1.48518122739952)\n      If (feature 0 <= -0.16459826996307)\n       Predict: 3.0\n      Else (feature 0 > -0.16459826996307)\n       Predict: 3.0\n     Else (feature 3 > 1.48518122739952)\n      Predict: 4.0\n    Else (feature 4 > -1.02893865416534)\n     Predict: 4.0\n  Else (feature 4 > -0.334642511215876)\n   If (feature 3 <= -1.78182495971615)\n    Predict: 2.0\n   Else (feature 3 > -1.78182495971615)\n    If (feature 0 <= -0.233858700080575)\n     Predict: 2.0\n    Else (feature 0 > -0.233858700080575)\n     If (feature 2 <= -0.176499701542154)\n      Predict: 2.0\n     Else (feature 2 > -0.176499701542154)\n      If (feature 0 <= -0.153597632201576)\n       Predict: 1.0\n      Else (feature 0 > -0.153597632201576)\n       Predict: 1.0\n\nimport org.apache.spark.mllib.tree.DecisionTree\nimport org.apache.spark.mllib.tree.model.DecisionTreeModel\nimport org.apache.spark.mllib.util.MLUtils\nimport org.apache.spark.mllib.regression.LabeledPoint\nfilename1: String = file:///home/user9/Data/Mean-Shift-PRL.csv/fourcres-d5.csv\nline1: org.apache.spark.rdd.RDD[String] = file:///home/user9/Data/Mean-Shift-PRL.csv/fourcres-d5.csv MapPartitionsRDD[158] at textFile at <console>:206\ndataheader1: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[159] at map at <console>:208\nfirst1: Array[String] = Array(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"label\")\ndata1: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[160] at filter at <console>:210\nlabeledData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPar..."},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":26}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"FCF60FB63E2E468DACCF3C0E684EBCD0"},"cell_type":"code","source":"val myTestData = testData.map(x => x.features)\nval mat: RowMatrix = new RowMatrix(myTestData)\n\n// Compute the top 10 principal components.\nval pc: Matrix = mat.computePrincipalComponents(3) // Principal components are stored in a local dense matrix.\n\n// Project the rows to the linear space spanned by the top 10 principal components.\nval projected = mat.multiply(pc)\n\nval rdd = projected.rows.collect()\nprintln(rdd)\nval ss = rdd.map{x => Array(x(0), x(1), x(2))}\n//val tt = Array(Array(1.9, 2.0), Array(1.9, 2.9))\nval predictions = labelAndPreds.map{x => x._1.toInt}.collect.toArray\nval win = smile.plot.plot(ss, predictions, '#',Palette.COLORS)","outputs":[{"name":"stdout","output_type":"stream","text":"[Lorg.apache.spark.mllib.linalg.Vector;@38262f45\nmyTestData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[205] at map at <console>:222\nmat: org.apache.spark.mllib.linalg.distributed.RowMatrix = org.apache.spark.mllib.linalg.distributed.RowMatrix@37fdaae7\npc: org.apache.spark.mllib.linalg.Matrix = \n-0.019183500750864835  -0.052510411745790964  -0.6779911247405064   \n-0.018259720270620054  -0.05984782764643046   -0.43908708770678373  \n-0.009722621693181568  -0.07761652348291659   -0.5790073887926817   \n0.844187217199075      -0.5346076425673649    0.035084285697957664  \n-0.5353055098349666    -0.837753685742582     0.10511945967718339   \nprojected: org.apache.spark.mllib.linalg.distributed.RowMatrix = org.apache.spark.mllib.linalg.distributed.RowMatrix@2767ff1f\nrdd: Array[org.apache.spark.mllib.linal..."},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":44}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"6B2E5D0B8B9945048100BDB538C48678"},"cell_type":"code","source":"//val labeledData = testData.map{x => Array(x.features, x.label)}\n\n//testData.take(5)\n\n/*\nval id_dt = new ExternalIndex(data.map(_.toString),labels_kmeansRDD.map(_.toString))\n\nprintln(\"czekanowskiDice=\"+DecisionTree.czekanowskiDice)\nprintln(\"rand=\"+DecisionTree.rand)\nprintln(\"rogersTanimoto=\"+DecisionTree.rogersTanimoto)\nprintln(\"folkesMallows=\"+DecisionTree.folkesMallows)\nprintln(\"jaccard=\"+DecisionTree.jaccard)\n/*println(\"kulczynski=\"+id_kmean2.kulczynski)\nprintln(\"mcNemar=\"+id_kmean2.mcNemar)\nprintln(\"russelRao=\"+id_kmean2.russelRao)\nprintln(\"sokalSneath1=\"+id_kmean2.sokalSneath1)\nprintln(\"sokalSneath2=\"+id_kmean2.sokalSneath2)\nprintln(\"recall=\"+id_kmean2.recall)\nprintln(\"precision=\"+id_kmean2.precision)\nprintln(\"czekanowskiDice=\"+id_kmean2.czekanowskiDice)\nprintln(\"rand=\"+id_kmean2.rand)\nprintln(\"rogersTanimoto=\"+id_kmean2.rogersTanimoto)\nprintln(\"folkesMallows=\"+id_kmean2.folkesMallows)\nprintln(\"jaccard=\"+id_kmean2.jaccard)\nprintln(\"kulczynski=\"+id_kmean2.kulczynski)\nprintln(\"mcNemar=\"+id_kmean2.mcNemar)\nprintln(\"russelRao=\"+id_kmean2.russelRao)\nprintln(\"sokalSneath1=\"+id_kmean2.sokalSneath1)\nprintln(\"sokalSneath2=\"+id_kmean2.sokalSneath2)\nprintln(\"recall=\"+id_kmean2.recall)\nprintln(\"precision=\"+id_kmean2.precision)*/","outputs":[{"ename":"Error","output_type":"error","traceback":["Incomplete (hint: check the parenthesis)"]}]},{"metadata":{"id":"D1B5EF5364BF45088619F797BD263C23"},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"6270B05E1A4741088712982548E49222"},"cell_type":"code","source":"import org.apache.spark.mllib.tree.RandomForest\nimport org.apache.spark.mllib.tree.model.RandomForestModel\nimport org.apache.spark.mllib.util.MLUtils\nimport org.apache.spark.ml.Pipeline\n// Train a RandomForest model.\n// Empty categoricalFeaturesInfo indicates all features are continuous.\nval numClasses = 5\nval categoricalFeaturesInfo = Map[Int, Int]()\nval numTrees = 3 // Use more in practice.\nval featureSubsetStrategy = \"auto\" // Let the algorithm choose.\nval impurity = \"gini\"\nval maxDepth = 4\nval maxBins = 32\n\nval rf = RandomForest.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo,\n  numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins)\n\n// Evaluate model on test instances and compute test error\nval labelAndPreds = testData.map { point =>\n  val prediction = rf.predict(point.features)\n  (point.label, prediction)\n}\nval testErr = labelAndPreds.filter(r => r._1 != r._2).count.toDouble / testData.count()\nprintln(\"Test Error = \" + testErr)\nprintln(\"Learned classification forest model:\\n\" + rf.toDebugString)\n\n//val vectorizer = VectorAssembler(inputCols=(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\"), outputCol=\"features\")\n\n","outputs":[{"name":"stdout","output_type":"stream","text":"Test Error = 0.00641025641025641\nLearned classification forest model:\nTreeEnsembleModel classifier with 3 trees\n\n  Tree 0:\n    If (feature 3 <= 0.647340780196024)\n     If (feature 4 <= 0.977671694775303)\n      If (feature 3 <= 0.449914673599503)\n       If (feature 4 <= -0.334642511215876)\n        Predict: 2.0\n       Else (feature 4 > -0.334642511215876)\n        Predict: 2.0\n      Else (feature 3 > 0.449914673599503)\n       Predict: 3.0\n     Else (feature 4 > 0.977671694775303)\n      Predict: 1.0\n    Else (feature 3 > 0.647340780196024)\n     If (feature 3 <= 1.19813503317784)\n      If (feature 4 <= -1.02893865416534)\n       Predict: 3.0\n      Else (feature 4 > -1.02893865416534)\n       If (feature 4 <= -0.871966864767872)\n        Predict: 4.0\n       Else (feature 4 > -0.871966864767872)\n        Predict: 1.0\n     Else (feature 3 > 1.19813503317784)\n      If (feature 4 <= -1.02893865416534)\n       If (feature 3 <= 1.40178885537589)\n        Predict: 3.0\n       Else (feature 3 > 1.40178885537589)\n        Predict: 4.0\n      Else (feature 4 > -1.02893865416534)\n       Predict: 4.0\n  Tree 1:\n    If (feature 4 <= -1.02893865416534)\n     Predict: 3.0\n    Else (feature 4 > -1.02893865416534)\n     If (feature 3 <= 0.919296908816909)\n      If (feature 3 <= -0.238633956639124)\n       If (feature 4 <= -0.334642511215876)\n        Predict: 2.0\n       Else (feature 4 > -0.334642511215876)\n        Predict: 1.0\n      Else (feature 3 > -0.238633956639124)\n       If (feature 4 <= -0.334642511215876)\n        Predict: 2.0\n       Else (feature 4 > -0.334642511215876)\n        Predict: 1.0\n     Else (feature 3 > 0.919296908816909)\n      If (feature 4 <= -0.685388734420948)\n       Predict: 4.0\n      Else (feature 4 > -0.685388734420948)\n       Predict: 1.0\n  Tree 2:\n    If (feature 4 <= -0.334642511215876)\n     If (feature 3 <= 0.232845891340284)\n      Predict: 2.0\n     Else (feature 3 > 0.232845891340284)\n      If (feature 4 <= -1.02893865416534)\n       If (feature 3 <= 1.48518122739952)\n        Predict: 3.0\n       Else (feature 3 > 1.48518122739952)\n        Predict: 4.0\n      Else (feature 4 > -1.02893865416534)\n       Predict: 4.0\n    Else (feature 4 > -0.334642511215876)\n     If (feature 0 <= -0.233858700080575)\n      Predict: 2.0\n     Else (feature 0 > -0.233858700080575)\n      If (feature 4 <= 0.977671694775303)\n       If (feature 2 <= -0.103215855571141)\n        Predict: 2.0\n       Else (feature 2 > -0.103215855571141)\n        Predict: 1.0\n      Else (feature 4 > 0.977671694775303)\n       Predict: 1.0\n\nimport org.apache.spark.mllib.tree.RandomForest\nimport org.apache.spark.mllib.tree.model.RandomForestModel\nimport org.apache.spark.mllib.util.MLUtils\nimport org.apache.spark.ml.Pipeline\nnumClasses: Int = 5\ncategoricalFeaturesInfo: scala.collection.immutable.Map[Int,Int] = Map()\nnumTrees: Int = 3\nfeatureSubsetStrategy: String = auto\nimpurity: String = gini\nmaxDepth: Int = 4\nmaxBins: Int = 32\nrf: org.apache.spark.mllib.tree.model.RandomForestModel = \nTreeEnsembleModel classifier with 3 trees\n\nlabelAndPreds: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[230] at map at <console>:207\ntestErr: Double = 0.00641025641025641\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":51}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"2B77F7604076415A91E0FB00BAAE2AE8"},"cell_type":"code","source":"\nval myTestData = testData.map(x => x.features)\nval mat: RowMatrix = new RowMatrix(myTestData)\n\n// Compute the top 10 principal components.\nval pc: Matrix = mat.computePrincipalComponents(3) // Principal components are stored in a local dense matrix.\n\n// Project the rows to the linear space spanned by the top 10 principal components.\nval projected = mat.multiply(pc)\n\nval rdd = projected.rows.collect()\nprintln(rdd)\nval ss = rdd.map{x => Array(x(0), x(1), x(2))}\n//val tt = Array(Array(1.9, 2.0), Array(1.9, 2.9))\nval predictions = labelAndPreds.map{x => x._1.toInt}.collect.toArray\nval win = smile.plot.plot(ss, predictions, '#',Palette.COLORS)","outputs":[{"name":"stdout","output_type":"stream","text":"[Lorg.apache.spark.mllib.linalg.Vector;@3f832383\nmyTestData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[232] at map at <console>:225\nmat: org.apache.spark.mllib.linalg.distributed.RowMatrix = org.apache.spark.mllib.linalg.distributed.RowMatrix@45e1b230\npc: org.apache.spark.mllib.linalg.Matrix = \n-0.019183500750864835  -0.052510411745790964  -0.6779911247405064   \n-0.018259720270620054  -0.05984782764643046   -0.43908708770678373  \n-0.009722621693181568  -0.07761652348291659   -0.5790073887926817   \n0.844187217199075      -0.5346076425673649    0.035084285697957664  \n-0.5353055098349666    -0.837753685742582     0.10511945967718339   \nprojected: org.apache.spark.mllib.linalg.distributed.RowMatrix = org.apache.spark.mllib.linalg.distributed.RowMatrix@669d2fdf\nrdd: Array[org.apache.spark.mllib.linal..."},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":52}]},{"metadata":{"id":"4540333E088C4D87877FD3A68F4084E4"},"cell_type":"markdown","source":"#LOGISTIC REGRESSION"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"FCF6C74B5784433A8B1CBE089BDA5721"},"cell_type":"code","source":"import org.apache.spark.mllib.classification.{LogisticRegressionModel, LogisticRegressionWithLBFGS}\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.util.MLUtils\n\n\n// Run training algorithm to build the model\nval lr = new LogisticRegressionWithLBFGS()\n  .setNumClasses(4)\n  .run(trainingData)\n\n// Compute raw scores on the test set.\nval predictionAndLabels = testData.map { case LabeledPoint(label, features) =>\n  val prediction = lr.predict(features)\n  (prediction, label)\n}\n\n// Get evaluation metrics.\nval metrics = new MulticlassMetrics(predictionAndLabels)","outputs":[{"name":"stdout","output_type":"stream","text":"org.apache.spark.SparkException: Input validation failed.\n\tat org.apache.spark.mllib.regression.GeneralizedLinearAlgorithm.run(GeneralizedLinearAlgorithm.scala:251)\n\tat org.apache.spark.mllib.regression.GeneralizedLinearAlgorithm.run(GeneralizedLinearAlgorithm.scala:229)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:196)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:218)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:220)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:222)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:224)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:226)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:228)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$fa17825793f04f8d2edd8765c45e2a6c$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:230)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:232)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:234)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:236)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:238)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:240)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:242)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:244)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:246)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:248)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:250)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:252)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:254)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:256)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:258)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:260)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:262)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:264)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$$$$$c57ec8bf9b0d5f6161b97741d596ff0$$$$wC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:266)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:268)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:270)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:272)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:274)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:276)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:278)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:280)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:282)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:284)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:286)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:288)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:290)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:292)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:294)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:296)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:298)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:300)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:302)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:304)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:306)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:308)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:310)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:312)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:314)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:316)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:318)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:320)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:322)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:324)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:326)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:328)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:330)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:332)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:334)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:336)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:338)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:340)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:342)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:344)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:346)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:348)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:350)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:352)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:354)\n\tat $iwC$$iwC$$iwC$$iwC.<init>(<console>:356)\n\tat $iwC$$iwC$$iwC.<init>(<console>:358)\n\tat $iwC$$iwC.<init>(<console>:360)\n\tat $iwC.<init>(<console>:362)\n\tat <init>(<console>:364)\n\tat .<init>(<console>:368)\n\tat .<clinit>(<console>)\n\tat .<init>(<console>:7)\n\tat .<clinit>(<console>)\n\tat $print(<console>)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n\tat notebook.kernel.Repl$$anonfun$6.apply(Repl.scala:200)\n\tat notebook.kernel.Repl$$anonfun$6.apply(Repl.scala:200)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:57)\n\tat scala.Console$.withOut(Console.scala:126)\n\tat notebook.kernel.Repl.evaluate(Repl.scala:199)\n\tat notebook.client.ReplCalculator$$anonfun$10$$anon$1$$anonfun$27.replEvaluate$1(ReplCalculator.scala:401)\n\tat notebook.client.ReplCalculator$$anonfun$10$$anon$1$$anonfun$27.apply(ReplCalculator.scala:414)\n\tat notebook.client.ReplCalculator$$anonfun$10$$anon$1$$anonfun$27.apply(ReplCalculator.scala:395)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)\n\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\n\n"}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false,"id":"F9CC62A3605540E6894C0500BDEF3FC5"},"cell_type":"code","source":"\nval myTestData = testData.map(x => x.features)\nval mat: RowMatrix = new RowMatrix(myTestData)\n\n// Compute the top 10 principal components.\nval pc: Matrix = mat.computePrincipalComponents(3) // Principal components are stored in a local dense matrix.\n\n// Project the rows to the linear space spanned by the top 10 principal components.\nval projected = mat.multiply(pc)\n\nval rdd = projected.rows.collect()\nprintln(rdd)\nval ss = rdd.map{x => Array(x(0), x(1), x(2))}\n\nval predictions = predictionAndLabels2.map{x => x._0.toInt}.collect.toArray\nval win = smile.plot.plot(ss, predictions, '#',Palette.COLORS)","outputs":[{"name":"stdout","output_type":"stream","text":"<console>:229: error: not found: value predictionAndLabels2\n       val predictions = predictionAndLabels2.map{x => x._0.toInt}.collect.toArray\n                         ^\n"}]},{"metadata":{"id":"3892C48B766C45A8A45FD22A6328743D"},"cell_type":"markdown","source":"#Cross Validation"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":true,"id":"13DB6A236ABD4FBAA489BDB57E9F92E6"},"cell_type":"code","source":"","outputs":[]}],"nbformat":4}